{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/efe/miniconda3/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from torch.utils.data import Subset\n",
    "from torchvision import models\n",
    "\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import threading\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], device='mps:0')\n",
      "MPS device found. - Apple Silicon GPU\n",
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "# ======================= PYTHON SETTINGS ======================= #\n",
    "# =======================   GPU or CPU    ======================= #\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# Check if GPU is available -> CUDA\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"There are %d GPU(s) available.\" % torch.cuda.device_count())\n",
    "    print(\"We will use the GPU:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "# Apple Silicon GPU\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    out = torch.ones(1, device=device)\n",
    "    print (out)\n",
    "    print (\"MPS device found. - Apple Silicon GPU\")\n",
    "else:\n",
    "    print (\"MPS device not found.\")\n",
    "\n",
    "\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# =======================   Ranom Seeds   ======================= #\n",
    "# Set random seed for reproducibility\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "# =============================================================== #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================= NORMALIZE PARAMS ======================= #\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),  # Resize images to a consistent size\n",
    "    transforms.ToTensor(),          # Convert images to tensors\n",
    "    transforms.Normalize(           # Normalize the images\n",
    "        # average values of the red, green, \n",
    "        # and blue channels across all images in the ImageNet dataset.\n",
    "        mean=[0.485, 0.456, 0.406], \n",
    "        # standard deviation of the red, green, and blue \n",
    "        # channels across all images in the ImageNet dataset.\n",
    "        std=[0.229, 0.224, 0.225]   \n",
    "    )\n",
    "])\n",
    "\n",
    "# ======================= DATA AUGMENTATION ======================= #\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),            # Resize images to a consistent size\n",
    "    transforms.RandomHorizontalFlip(),        # Random horizontal flipping\n",
    "    transforms.RandomRotation(15),            # Random rotation by 10 degrees\n",
    "    transforms.ColorJitter(brightness=0.2,    # Adjust brightness, contrast, saturation, and hue\n",
    "                           contrast=0.2,\n",
    "                           saturation=0.2,\n",
    "                           hue=0.1),\n",
    "    transforms.ToTensor(),                    # Convert images to tensors\n",
    "    transforms.Normalize(                     # Normalize the images\n",
    "        mean=[0.485, 0.456, 0.406],           # Mean for ImageNet dataset\n",
    "        std=[0.229, 0.224, 0.225]             # Standard deviation for ImageNet dataset\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================= LOAD MAIN DATASET ======================= #\n",
    "# Download and load the Food101 dataset\n",
    "train_dataset = torchvision.datasets.Food101(\n",
    "    root='./data',                 # Directory to save the downloaded data\n",
    "    split='train',\n",
    "    download=True,                 # Download the data if not present\n",
    "    transform=train_transform            # Apply the train_transform to the data\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.Food101(\n",
    "    root='./data',                 # Directory to save the downloaded data\n",
    "    split='test',\n",
    "    download=True,                 # Download the data if not present\n",
    "    transform=transform            # Apply the transform to the data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_labels_from_loader(loader):\n",
    "#     labels = []\n",
    "#     for _, label in loader:\n",
    "#         labels.extend(label.tolist())\n",
    "#     return labels\n",
    "\n",
    "# def get_subset_with_n_classes(original_dataset, n_classes, batch_size=64):\n",
    "#     # Check if the dataset is a Subset\n",
    "#     if isinstance(original_dataset, Subset):\n",
    "#         # Create a DataLoader to extract labels from the Subset\n",
    "#         subset_loader = DataLoader(original_dataset, batch_size=batch_size, shuffle=False)\n",
    "#         # Extract labels\n",
    "#         targets = get_labels_from_loader(subset_loader)\n",
    "#     else:\n",
    "#         # Try to access labels through the targets attribute\n",
    "#         try:\n",
    "#             targets = original_dataset.targets\n",
    "#         except AttributeError:\n",
    "#             # If targets attribute doesn't exist, use __getitem__ method\n",
    "#             targets = [original_dataset[i][1] for i in range(len(original_dataset))]\n",
    "\n",
    "#     # Find the unique classes and select the first n\n",
    "#     unique_classes = torch.unique(torch.tensor(targets))\n",
    "#     selected_classes = unique_classes[:n_classes].tolist()\n",
    "\n",
    "#     # Get the indices of samples belonging to the selected classes\n",
    "#     selected_indices = [i for i, t in enumerate(targets) if t in selected_classes]\n",
    "\n",
    "#     # Handle if the dataset is already a Subset\n",
    "#     if isinstance(original_dataset, Subset):\n",
    "#         # Adjust indices to map to the original dataset\n",
    "#         original_indices = [original_dataset.indices[i] for i in selected_indices]\n",
    "#         # Create a new Subset from the original dataset\n",
    "#         subset = Subset(original_dataset.dataset, original_indices)\n",
    "#     else:\n",
    "#         # Create a new Subset\n",
    "#         subset = Subset(original_dataset, selected_indices)\n",
    "\n",
    "#     return subset\n",
    "\n",
    "def get_labels_from_loader(loader):\n",
    "    # Concatenate all labels into a single NumPy array for efficiency\n",
    "    return np.concatenate([labels.numpy() for _, labels in loader])\n",
    "\n",
    "def get_subset_with_n_classes(original_dataset, n_classes, batch_size=64):\n",
    "    # Check if the dataset is a Subset\n",
    "    if isinstance(original_dataset, Subset):\n",
    "        # Create a DataLoader with a larger batch size for efficiency\n",
    "        subset_loader = DataLoader(original_dataset, batch_size=batch_size, shuffle=False)\n",
    "        targets = get_labels_from_loader(subset_loader)\n",
    "    else:\n",
    "        # Try to access labels through the targets attribute\n",
    "        # try:\n",
    "        #     targets = np.array(original_dataset.targets)\n",
    "        # except AttributeError:\n",
    "            # Use list comprehension and NumPy for efficient label extraction\n",
    "        targets = np.array([original_dataset[i][1] for i in range(len(original_dataset))])\n",
    "\n",
    "    # Find the unique classes and select the first n\n",
    "    unique_classes = np.unique(targets)\n",
    "    selected_classes = unique_classes[:n_classes]\n",
    "\n",
    "    # Vectorized operation for selecting indices\n",
    "    selected_indices = np.where(np.isin(targets, selected_classes))[0]\n",
    "\n",
    "    # Handle if the dataset is already a Subset\n",
    "    if isinstance(original_dataset, Subset):\n",
    "        original_indices = original_dataset.indices[selected_indices]\n",
    "        subset = Subset(original_dataset.dataset, original_indices)\n",
    "    else:\n",
    "        subset = Subset(original_dataset, selected_indices)\n",
    "\n",
    "    return subset\n",
    "\n",
    "\n",
    "\n",
    "# Get a subset with the first n classes\n",
    "n = 101  # For example, get the first 5 classes\n",
    "# subset_train = get_subset_with_n_classes(train_dataset, n)\n",
    "# subset_test =  get_subset_with_n_classes(test_dataset, n)\n",
    "\n",
    "subset_train = train_dataset\n",
    "subset_test = test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subset_test tensor([[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "         [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "         [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "         ...,\n",
      "         [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "         [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "         [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
      "\n",
      "        [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         ...,\n",
      "         [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
      "\n",
      "        [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "         [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "         [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "         ...,\n",
      "         [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "         [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "         [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]])\n",
      "subset_test 23\n"
     ]
    }
   ],
   "source": [
    "# test for small sets\n",
    "\n",
    "print(\"subset_test\", subset_train[0][0])\n",
    "print(\"subset_test\", subset_train[0][1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset length: 75750\n",
      "Test dataset length: 25250\n",
      "Classes: ['apple_pie', 'baby_back_ribs', 'baklava', 'beef_carpaccio', 'beef_tartare', 'beet_salad', 'beignets', 'bibimbap', 'bread_pudding', 'breakfast_burrito', 'bruschetta', 'caesar_salad', 'cannoli', 'caprese_salad', 'carrot_cake', 'ceviche', 'cheese_plate', 'cheesecake', 'chicken_curry', 'chicken_quesadilla', 'chicken_wings', 'chocolate_cake', 'chocolate_mousse', 'churros', 'clam_chowder', 'club_sandwich', 'crab_cakes', 'creme_brulee', 'croque_madame', 'cup_cakes', 'deviled_eggs', 'donuts', 'dumplings', 'edamame', 'eggs_benedict', 'escargots', 'falafel', 'filet_mignon', 'fish_and_chips', 'foie_gras', 'french_fries', 'french_onion_soup', 'french_toast', 'fried_calamari', 'fried_rice', 'frozen_yogurt', 'garlic_bread', 'gnocchi', 'greek_salad', 'grilled_cheese_sandwich', 'grilled_salmon', 'guacamole', 'gyoza', 'hamburger', 'hot_and_sour_soup', 'hot_dog', 'huevos_rancheros', 'hummus', 'ice_cream', 'lasagna', 'lobster_bisque', 'lobster_roll_sandwich', 'macaroni_and_cheese', 'macarons', 'miso_soup', 'mussels', 'nachos', 'omelette', 'onion_rings', 'oysters', 'pad_thai', 'paella', 'pancakes', 'panna_cotta', 'peking_duck', 'pho', 'pizza', 'pork_chop', 'poutine', 'prime_rib', 'pulled_pork_sandwich', 'ramen', 'ravioli', 'red_velvet_cake', 'risotto', 'samosa', 'sashimi', 'scallops', 'seaweed_salad', 'shrimp_and_grits', 'spaghetti_bolognese', 'spaghetti_carbonara', 'spring_rolls', 'steak', 'strawberry_shortcake', 'sushi', 'tacos', 'takoyaki', 'tiramisu', 'tuna_tartare', 'waffles']\n",
      "Number of classes: 101\n",
      "===============================================\n",
      "Sample image shape: torch.Size([3, 256, 256])\n",
      "Sample image label [0][1]: 23\n",
      "Sample image class: churros\n"
     ]
    }
   ],
   "source": [
    "# =======================     DATA INFO    ======================= #\n",
    "print('Train dataset length:',      len(train_dataset))\n",
    "print('Test dataset length:',       len(test_dataset))\n",
    "print('Classes:',                   train_dataset.classes)\n",
    "print('Number of classes:',         len(train_dataset.classes))\n",
    "print(\"===============================================\")\n",
    "print('Sample image shape:',        np.shape(train_dataset[0][0]))\n",
    "# print('Sample image shape [0][0]:', train_dataset[0][0])\n",
    "print('Sample image label [0][1]:', train_dataset[0][1])\n",
    "print('Sample image class:',        train_dataset.classes[train_dataset[0][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def display_image(dataset, index):\n",
    "#     plt.imshow(dataset[index][0])                       # Plot the image\n",
    "#     plt.title(train_dataset.classes[dataset[index][1]]) # Set the title \n",
    "# ======================== DISPLAY IMAGE (FROM MAIN DATASET) ======================== #\n",
    "def display_image(dataset, index):\n",
    "    image, label = dataset[index]\n",
    "    image = to_pil_image(image)\n",
    "    plt.imshow(image)\n",
    "    plt.title(train_dataset.classes[label])\n",
    "\n",
    "display_image(train_dataset, 33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHOW AN IMAGE FROM THE SUBSET\n",
    "\n",
    "def display_image(dataset, index):\n",
    "    image, label = dataset[index]\n",
    "    image = to_pil_image(image)\n",
    "    plt.imshow(image)\n",
    "    plt.title(train_dataset.classes[label])\n",
    "\n",
    "display_image(subset_train, 2620)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================ SAMPLE IMAGE FOR ALL CLASSES ================ #\n",
    "def display_each_class(dataset):\n",
    "    plt.figure(figsize=(256, 256))  # Adjust the figure size as needed\n",
    "    for idx in range(0, len(train_dataset.classes)):\n",
    "        plt.subplot(26, 4, idx+1)\n",
    "        plt.imshow(dataset[idx * 750][0])  # Indexing starts from 0\n",
    "        plt.title(dataset.classes[dataset[idx * 750][1]])\n",
    "        # plt.xticks([])\n",
    "        # plt.yticks([])\n",
    "\n",
    "    plt.tight_layout()  # Move this outside the loop\n",
    "    # plt.show()\n",
    "    plt.savefig(\"output.png\")\n",
    "\n",
    "display_each_class(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General function to display the histogram of the images\n",
    "def list_image_paths(root_dir = \"data/food-101/images\", extensions=['.jpg', '.jpeg', '.png']):\n",
    "    image_paths = []\n",
    "\n",
    "    for root, dirs, files in os.walk(root_dir):\n",
    "        #write in red\n",
    "        # print('\\033[91m' + root)\n",
    "        for file in files:\n",
    "            #write in blue\n",
    "            # print('\\033[94m' + file)\n",
    "    \n",
    "            if any(file.lower().endswith(ext) for ext in extensions):\n",
    "                image_paths.append(os.path.join(root, file))\n",
    "                break\n",
    "            \n",
    "\n",
    "    return image_paths\n",
    "\n",
    "def display_histogram(image_paths):\n",
    "    # Load images and extract pixel values\n",
    "    images = [np.array(Image.open(image_path).convert(\"RGB\")) for image_path in image_paths]\n",
    "    \n",
    "    # Flatten the 3D array of pixel values into a 1D array\n",
    "    pixel_values_flat = np.concatenate([image.flatten() for image in images])\n",
    "\n",
    "    # print('Total number of pixels:', len(pixel_values_flat))\n",
    "\n",
    "    # Make a histogram for the pixel values\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.hist(pixel_values_flat, bins=20, range=(0, 255), color='blue', edgecolor='black')\n",
    "    plt.title('Distribution of Pixel Intensities in the Dataset')\n",
    "    plt.xlabel('Pixel Value')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "\n",
    "test = list_image_paths()\n",
    "# print(len(test))\n",
    "# print(test[0:101])\n",
    "display_histogram(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================   CNN MODEL    ======================= #\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        # Input shape: [batch_size, 3, 256, 256]\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        # Fully connected layer\n",
    "        self.fc1 = nn.Linear(64 * 64 * 64, 512)\n",
    "        self.fc2 = nn.Linear(512, 512)\n",
    "        self.fc3 = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 64 * 64)  # Flatten the tensor\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================   CNN MODEL    ======================= #\n",
    "class SimpleCNN2(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SimpleCNN2, self).__init__()\n",
    "        # Input shape: [batch_size, 3, 256, 256]\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "        # Fully connected layer\n",
    "        self.fc1 = nn.Linear(128 * 128 * 128, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 1024)\n",
    "        self.fc3 = nn.Linear(1024, 1024)\n",
    "        self.fc4 = nn.Linear(1024, 512)\n",
    "        self.fc5 = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 128 * 128 * 128)  # Flatten the tensor\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = self.fc5(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN3(nn.Module):\n",
    "    def __init__(self, num_classes, dropout_prob=0.2):\n",
    "        super(SimpleCNN3, self).__init__()\n",
    "        # Input shape: [batch_size, 3, 256, 256]\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)  # BatchNorm after the first convolutional layer\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)  # BatchNorm after the second convolutional layer\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)  # BatchNorm after the third convolutional layer\n",
    "        # Fully connected layer\n",
    "        self.fc1 = nn.Linear(128 * 128 * 128, 1024)\n",
    "        self.bn_fc1 = nn.BatchNorm1d(1024)  # BatchNorm after the first fully connected layer\n",
    "        self.dropout1 = nn.Dropout(dropout_prob)  # Dropout before the first fully connected layer\n",
    "        self.fc2 = nn.Linear(1024, 1024)\n",
    "        self.bn_fc2 = nn.BatchNorm1d(1024)  # BatchNorm after the second fully connected layer\n",
    "        self.dropout2 = nn.Dropout(dropout_prob)  # Dropout before the second fully connected layer\n",
    "        self.fc3 = nn.Linear(1024, 1024)\n",
    "        self.bn_fc3 = nn.BatchNorm1d(1024)  # BatchNorm after the third fully connected layer\n",
    "        self.dropout3 = nn.Dropout(dropout_prob)  # Dropout before the third fully connected layer\n",
    "        self.fc4 = nn.Linear(1024, 1024)\n",
    "        self.fc5 = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))  # Apply BatchNorm after the first convolutional layer\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))  # Apply BatchNorm after the second convolutional layer\n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))  # Apply BatchNorm after the third convolutional layer\n",
    "        x = x.view(-1, 128 * 128 * 128)  # Flatten the tensor\n",
    "        x = F.relu(self.bn_fc1(self.fc1(x)))  # Apply BatchNorm after the first fully connected layer\n",
    "        x = self.dropout1(x)  # Apply dropout before the first fully connected layer\n",
    "        x = F.relu(self.bn_fc2(self.fc2(x)))  # Apply BatchNorm after the second fully connected layer\n",
    "        x = self.dropout2(x)  # Apply dropout before the second fully connected layer\n",
    "        x = F.relu(self.bn_fc3(self.fc3(x)))  # Apply BatchNorm after the third fully connected layer\n",
    "        x = self.dropout3(x)  # Apply dropout before the third fully connected layer\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = self.fc5(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageClassifier(nn.Module):\n",
    "   def __init__(self, num_classes):\n",
    "       super(CustomImageClassifier, self).__init__()\n",
    "      \n",
    "       # Load a pre-trained model (e.g., ResNet)\n",
    "       self.model = models.resnet18(pretrained=True)\n",
    "      \n",
    "       # Freeze the parameters of the model\n",
    "       for param in self.model.parameters():\n",
    "           param.requires_grad = False\n",
    "\n",
    "\n",
    "       # Assuming ResNet18 is used, the in_features for the first added linear layer\n",
    "       in_features = self.model.fc.in_features\n",
    "\n",
    "\n",
    "       # Replace the fully connected layer\n",
    "       self.model.fc = nn.Sequential(\n",
    "           nn.Linear(in_features, 512),\n",
    "           nn.ReLU(),\n",
    "           nn.BatchNorm1d(512),\n",
    "           nn.Dropout(0.5),\n",
    "           nn.Linear(512, 256),\n",
    "           nn.ReLU(),\n",
    "           nn.BatchNorm1d(256),\n",
    "           nn.Dropout(0.5),\n",
    "           nn.Linear(256, num_classes)\n",
    "       )\n",
    "\n",
    "\n",
    "   def forward(self, x):\n",
    "       return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================= SMALL MODEL TRAINING FOR 5 CLASSES ======================= #\n",
    "# Hyperparameters\n",
    "num_epochs = 20\n",
    "batch_size = 32\n",
    "num_classes = 5 # ? temporary 5\n",
    "learning_rate = 0.001\n",
    "num_folds = 5  # Number of folds for K-fold cross-validation\n",
    "\n",
    "# Initialize KFold for cross-validation\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=seed)\n",
    "\n",
    "best_model = None\n",
    "best_val_accuracy = 0.0\n",
    "\n",
    "for fold, (train_indices, val_indices) in enumerate(kf.split(subset_train)):\n",
    "    print(f\"Fold {fold + 1}/{num_folds}\")\n",
    "\n",
    "    # Initialize model, loss function, and optimizer\n",
    "    model = CustomImageClassifier(num_classes)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Split the data into training and validation sets for this fold\n",
    "    train_sampler = torch.utils.data.SubsetRandomSampler(train_indices)\n",
    "    val_sampler = torch.utils.data.SubsetRandomSampler(val_indices)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(subset_train, batch_size=batch_size, sampler=train_sampler)\n",
    "    val_loader = torch.utils.data.DataLoader(subset_train, batch_size=batch_size, sampler=val_sampler)\n",
    "\n",
    "    for epoch in tqdm(range(num_epochs), desc=\"Training\", unit=\"epoch\"):\n",
    "        # Training loop\n",
    "        model.train()\n",
    "        for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{num_epochs}\", unit=\"batch\"):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validation loop\n",
    "        model.eval()\n",
    "        total_correct = 0\n",
    "        total_samples = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in tqdm(val_loader, desc=f\"Epoch {epoch + 1}/{num_epochs} (Validation)\", unit=\"batch\"):\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total_samples += labels.size(0)\n",
    "                total_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_accuracy = total_correct / total_samples\n",
    "        \n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}] - Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "        # Check if this model has the best validation accuracy\n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy\n",
    "            best_model = model.state_dict()\n",
    "\n",
    "# After K-fold cross-validation, use the best model for testing\n",
    "model.load_state_dict(best_model)\n",
    "model.eval()\n",
    "\n",
    "# Save the best model\n",
    "torch.save(best_model, 'bestmodel.pt')\n",
    "\n",
    "# Define the data loader for testing\n",
    "test_loader = torch.utils.data.DataLoader(subset_test, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Testing loop\n",
    "model.eval()\n",
    "total_correct = 0\n",
    "total_samples = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total_samples += labels.size(0)\n",
    "        total_correct += (predicted == labels).sum().item()\n",
    "\n",
    "test_accuracy = total_correct / total_samples\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/efe/miniconda3/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/efe/miniconda3/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n",
      "Fold 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/20 [00:00<?, ?epoch/s]/Users/efe/miniconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training:   5%|▌         | 1/20 [02:45<52:25, 165.54s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20] - Validation Accuracy: 0.4523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 2/20 [05:30<49:38, 165.49s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20] - Validation Accuracy: 0.4782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▌        | 3/20 [08:14<46:41, 164.78s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20] - Validation Accuracy: 0.4855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 4/20 [10:58<43:51, 164.48s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20] - Validation Accuracy: 0.4887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  25%|██▌       | 5/20 [13:42<41:04, 164.31s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20] - Validation Accuracy: 0.4939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  30%|███       | 6/20 [16:26<38:15, 163.95s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20] - Validation Accuracy: 0.4981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  35%|███▌      | 7/20 [19:10<35:32, 164.07s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20] - Validation Accuracy: 0.4992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  40%|████      | 8/20 [21:53<32:45, 163.81s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20] - Validation Accuracy: 0.5062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  45%|████▌     | 9/20 [24:37<30:03, 163.92s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20] - Validation Accuracy: 0.5099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  50%|█████     | 10/20 [27:23<27:24, 164.48s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20] - Validation Accuracy: 0.5082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  55%|█████▌    | 11/20 [30:07<24:38, 164.28s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20] - Validation Accuracy: 0.5102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  60%|██████    | 12/20 [32:48<21:45, 163.22s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20] - Validation Accuracy: 0.5101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  65%|██████▌   | 13/20 [35:30<19:00, 162.92s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20] - Validation Accuracy: 0.5139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  70%|███████   | 14/20 [38:13<16:17, 163.00s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20] - Validation Accuracy: 0.5183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  75%|███████▌  | 15/20 [40:55<13:33, 162.67s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20] - Validation Accuracy: 0.5156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  80%|████████  | 16/20 [43:38<10:50, 162.74s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20] - Validation Accuracy: 0.5182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|████████▌ | 17/20 [46:32<08:18, 166.10s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/20] - Validation Accuracy: 0.5181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  90%|█████████ | 18/20 [49:43<05:47, 173.61s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/20] - Validation Accuracy: 0.5181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  95%|█████████▌| 19/20 [52:33<02:52, 172.54s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20] - Validation Accuracy: 0.5171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 20/20 [55:20<00:00, 166.02s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20] - Validation Accuracy: 0.5205\n",
      "Fold 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:   5%|▌         | 1/20 [02:46<52:47, 166.73s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20] - Validation Accuracy: 0.4543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 2/20 [05:33<49:57, 166.56s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20] - Validation Accuracy: 0.4744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▌        | 3/20 [08:20<47:18, 166.95s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20] - Validation Accuracy: 0.4921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 4/20 [11:06<44:24, 166.53s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20] - Validation Accuracy: 0.4937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  25%|██▌       | 5/20 [13:51<41:32, 166.15s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20] - Validation Accuracy: 0.5042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  30%|███       | 6/20 [16:37<38:43, 165.99s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20] - Validation Accuracy: 0.5054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  35%|███▌      | 7/20 [19:21<35:47, 165.22s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20] - Validation Accuracy: 0.5105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  40%|████      | 8/20 [22:04<32:54, 164.51s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20] - Validation Accuracy: 0.5089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  45%|████▌     | 9/20 [24:47<30:06, 164.27s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20] - Validation Accuracy: 0.5061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  50%|█████     | 10/20 [27:34<27:28, 164.90s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20] - Validation Accuracy: 0.5140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  55%|█████▌    | 11/20 [30:19<24:45, 165.05s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20] - Validation Accuracy: 0.5176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  60%|██████    | 12/20 [33:04<22:00, 165.06s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20] - Validation Accuracy: 0.5196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  65%|██████▌   | 13/20 [35:49<19:13, 164.85s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20] - Validation Accuracy: 0.5176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  70%|███████   | 14/20 [40:30<19:59, 199.96s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20] - Validation Accuracy: 0.5190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  75%|███████▌  | 15/20 [43:36<16:18, 195.78s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20] - Validation Accuracy: 0.5222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  80%|████████  | 16/20 [47:08<13:22, 200.73s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20] - Validation Accuracy: 0.5245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|████████▌ | 17/20 [50:04<09:40, 193.40s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/20] - Validation Accuracy: 0.5221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  90%|█████████ | 18/20 [52:59<06:15, 187.66s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/20] - Validation Accuracy: 0.5251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  95%|█████████▌| 19/20 [55:51<03:03, 183.08s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20] - Validation Accuracy: 0.5220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 20/20 [58:44<00:00, 176.23s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20] - Validation Accuracy: 0.5256\n",
      "Fold 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:   5%|▌         | 1/20 [02:52<54:37, 172.48s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20] - Validation Accuracy: 0.4538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 2/20 [05:47<52:10, 173.90s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20] - Validation Accuracy: 0.4715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▌        | 3/20 [08:42<49:23, 174.30s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20] - Validation Accuracy: 0.4817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 4/20 [11:34<46:15, 173.45s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20] - Validation Accuracy: 0.4903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  25%|██▌       | 5/20 [14:26<43:15, 173.01s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20] - Validation Accuracy: 0.4933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  30%|███       | 6/20 [17:16<40:09, 172.12s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20] - Validation Accuracy: 0.4978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  35%|███▌      | 7/20 [20:08<37:16, 172.00s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20] - Validation Accuracy: 0.5022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  40%|████      | 8/20 [22:59<34:21, 171.78s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20] - Validation Accuracy: 0.5042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  45%|████▌     | 9/20 [25:53<31:36, 172.42s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20] - Validation Accuracy: 0.5057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  50%|█████     | 10/20 [28:40<28:26, 170.70s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20] - Validation Accuracy: 0.5069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  55%|█████▌    | 11/20 [31:31<25:37, 170.84s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20] - Validation Accuracy: 0.5112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  60%|██████    | 12/20 [34:20<22:40, 170.07s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20] - Validation Accuracy: 0.5094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  65%|██████▌   | 13/20 [37:06<19:43, 169.03s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20] - Validation Accuracy: 0.5143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  70%|███████   | 14/20 [39:56<16:56, 169.34s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20] - Validation Accuracy: 0.5120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  75%|███████▌  | 15/20 [43:05<14:35, 175.05s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20] - Validation Accuracy: 0.5150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  80%|████████  | 16/20 [46:37<12:25, 186.33s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20] - Validation Accuracy: 0.5191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|████████▌ | 17/20 [49:39<09:14, 184.98s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/20] - Validation Accuracy: 0.5165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  90%|█████████ | 18/20 [52:31<06:01, 180.97s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/20] - Validation Accuracy: 0.5129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  95%|█████████▌| 19/20 [55:23<02:58, 178.47s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20] - Validation Accuracy: 0.5191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 20/20 [58:20<00:00, 175.05s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20] - Validation Accuracy: 0.5214\n",
      "Fold 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:   5%|▌         | 1/20 [02:53<54:58, 173.61s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20] - Validation Accuracy: 0.4499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 2/20 [05:47<52:04, 173.59s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20] - Validation Accuracy: 0.4754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▌        | 3/20 [08:39<48:58, 172.87s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20] - Validation Accuracy: 0.4830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 4/20 [11:28<45:41, 171.32s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20] - Validation Accuracy: 0.4855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  25%|██▌       | 5/20 [14:16<42:33, 170.23s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20] - Validation Accuracy: 0.4902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  30%|███       | 6/20 [16:59<39:07, 167.68s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20] - Validation Accuracy: 0.4985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  35%|███▌      | 7/20 [19:42<36:00, 166.20s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20] - Validation Accuracy: 0.5001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  40%|████      | 8/20 [22:25<33:04, 165.39s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20] - Validation Accuracy: 0.5017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  45%|████▌     | 9/20 [25:12<30:21, 165.63s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20] - Validation Accuracy: 0.5096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  50%|█████     | 10/20 [27:56<27:32, 165.28s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20] - Validation Accuracy: 0.5046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  55%|█████▌    | 11/20 [30:40<24:43, 164.86s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20] - Validation Accuracy: 0.5036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  60%|██████    | 12/20 [33:23<21:55, 164.41s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20] - Validation Accuracy: 0.5107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  65%|██████▌   | 13/20 [36:07<19:09, 164.29s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20] - Validation Accuracy: 0.5072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  70%|███████   | 14/20 [38:50<16:22, 163.82s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20] - Validation Accuracy: 0.5084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  75%|███████▌  | 15/20 [41:33<13:38, 163.67s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20] - Validation Accuracy: 0.5101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  80%|████████  | 16/20 [44:17<10:53, 163.48s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20] - Validation Accuracy: 0.5145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|████████▌ | 17/20 [47:02<08:12, 164.14s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/20] - Validation Accuracy: 0.5161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  90%|█████████ | 18/20 [50:03<05:38, 169.25s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/20] - Validation Accuracy: 0.5174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  95%|█████████▌| 19/20 [53:28<02:59, 179.83s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20] - Validation Accuracy: 0.5182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 20/20 [56:23<00:00, 169.17s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20] - Validation Accuracy: 0.5130\n",
      "Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:   5%|▌         | 1/20 [02:48<53:19, 168.38s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20] - Validation Accuracy: 0.4442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 2/20 [05:38<50:48, 169.33s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20] - Validation Accuracy: 0.4726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▌        | 3/20 [08:26<47:51, 168.88s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20] - Validation Accuracy: 0.4884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 4/20 [11:13<44:50, 168.14s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20] - Validation Accuracy: 0.4890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  25%|██▌       | 5/20 [13:59<41:49, 167.28s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20] - Validation Accuracy: 0.4939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  30%|███       | 6/20 [16:43<38:46, 166.16s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20] - Validation Accuracy: 0.4992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  35%|███▌      | 7/20 [19:28<35:54, 165.77s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20] - Validation Accuracy: 0.5030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  40%|████      | 8/20 [22:12<33:03, 165.25s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20] - Validation Accuracy: 0.5041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  45%|████▌     | 9/20 [24:56<30:14, 164.98s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20] - Validation Accuracy: 0.5050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  50%|█████     | 10/20 [27:40<27:24, 164.44s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20] - Validation Accuracy: 0.5032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  55%|█████▌    | 11/20 [30:24<24:38, 164.31s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20] - Validation Accuracy: 0.5098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  60%|██████    | 12/20 [33:08<21:53, 164.18s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20] - Validation Accuracy: 0.5125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  65%|██████▌   | 13/20 [35:52<19:09, 164.14s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20] - Validation Accuracy: 0.5123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  70%|███████   | 14/20 [38:36<16:25, 164.23s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20] - Validation Accuracy: 0.5135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  75%|███████▌  | 15/20 [41:20<13:40, 164.09s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20] - Validation Accuracy: 0.5161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  80%|████████  | 16/20 [44:03<10:55, 163.85s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20] - Validation Accuracy: 0.5166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|████████▌ | 17/20 [46:49<08:13, 164.38s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/20] - Validation Accuracy: 0.5166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  90%|█████████ | 18/20 [49:36<05:30, 165.22s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/20] - Validation Accuracy: 0.5190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  95%|█████████▌| 19/20 [52:20<02:44, 164.75s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20] - Validation Accuracy: 0.5211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 20/20 [55:03<00:00, 165.20s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20] - Validation Accuracy: 0.5232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ======================= BIG MODEL TRAINING FOR 101 CLASSES ======================= #\n",
    "\n",
    "torch.backends.cudnn.enabled = False\n",
    "\n",
    "print(\"Device:\", device)\n",
    "if device == torch.device(\"cpu\"):\n",
    "    print(\"Training on CPU - not recommended!\")\n",
    "    print(\"ABORTING\")\n",
    "    exit()\n",
    "\n",
    "# Hyperparameters\n",
    "num_epochs = 20\n",
    "batch_size = 32\n",
    "num_classes = 101\n",
    "learning_rate = 0.001\n",
    "num_folds = 5\n",
    "seed = 42\n",
    "\n",
    "# Initialize KFold for cross-validation\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=seed)\n",
    "\n",
    "best_model = None\n",
    "best_val_accuracy = 0.0\n",
    "\n",
    "for fold, (train_indices, val_indices) in enumerate(kf.split(subset_train)):\n",
    "    print(f\"Fold {fold + 1}/{num_folds}\")\n",
    "\n",
    "    # Initialize model, loss function, and optimizer\n",
    "    model = CustomImageClassifier(num_classes).to(device)\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Split the data into training and validation sets for this fold\n",
    "    train_sampler = torch.utils.data.SubsetRandomSampler(train_indices)\n",
    "    val_sampler = torch.utils.data.SubsetRandomSampler(val_indices)\n",
    "\n",
    "    train_loader = DataLoader(subset_train, batch_size=batch_size, sampler=train_sampler, pin_memory=True, num_workers=8)\n",
    "    val_loader = DataLoader(subset_train, batch_size=batch_size, sampler=val_sampler, pin_memory=True, num_workers=8)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in tqdm(range(num_epochs), desc=\"Training\", unit=\"epoch\"):\n",
    "        model.train()\n",
    "        for images, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            with torch.cuda.amp.autocast(\"mps\"):\n",
    "                outputs = model(images.to(device))\n",
    "                loss = criterion(outputs, labels.to(device))\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validation loop\n",
    "        model.eval()\n",
    "        total_correct = 0\n",
    "        total_samples = 0\n",
    "        with torch.cuda.amp.autocast(\"mps\"):\n",
    "            for images, labels in val_loader:\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total_samples += labels.size(0)\n",
    "                total_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_accuracy = total_correct / total_samples\n",
    "\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}] - Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "        # Check if this model has the best validation accuracy\n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy\n",
    "            best_model = model.state_dict()\n",
    "\n",
    "# After K-fold cross-validation, use the best model for testing\n",
    "model.load_state_dict(best_model)\n",
    "model.eval()\n",
    "\n",
    "# Save the best model\n",
    "torch.save(best_model, 'bestmodel.pt')\n",
    "\n",
    "# Define the data loader for testing\n",
    "test_loader = DataLoader(subset_test, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=8)\n",
    "\n",
    "# Testing loop\n",
    "model.eval()\n",
    "total_correct = 0\n",
    "total_samples = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images.to(device))\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total_samples += labels.size(0)\n",
    "        total_correct += (predicted == labels.to(device)).sum().item()\n",
    "\n",
    "test_accuracy = total_correct / total_samples\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nihat - 21 Ocak - 101 class \n",
    "class CustomImageClassifier2(nn.Module):\n",
    "   def __init__(self, num_classes):\n",
    "       super(CustomImageClassifier2, self).__init__()\n",
    "      \n",
    "       # Load a pre-trained model (e.g., ResNet)\n",
    "       self.model = models.resnet50(pretrained=True)\n",
    "      \n",
    "       # Freeze the parameters of the model\n",
    "       for param in self.model.parameters():\n",
    "           param.requires_grad = False\n",
    "\n",
    "\n",
    "       # Assuming ResNet18 is used, the in_features for the first added linear layer\n",
    "       in_features = self.model.fc.in_features\n",
    "\n",
    "\n",
    "       # Replace the fully connected layer\n",
    "       self.model.fc = nn.Sequential(\n",
    "           nn.Linear(in_features, 1024),\n",
    "           nn.ReLU(),\n",
    "           nn.BatchNorm1d(1024),\n",
    "           nn.Dropout(0.5),\n",
    "           nn.Linear(1024, 512),\n",
    "           nn.ReLU(),\n",
    "           nn.BatchNorm1d(512),\n",
    "           nn.Dropout(0.5),\n",
    "           nn.Linear(512, 256),\n",
    "           nn.ReLU(),\n",
    "           nn.BatchNorm1d(256),\n",
    "           nn.Dropout(0.5),\n",
    "           nn.Linear(256, num_classes)\n",
    "       )\n",
    "\n",
    "\n",
    "   def forward(self, x):\n",
    "       return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n",
      "Fold 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nihat/mambaforge/envs/2023-06-05-neuralnetworks/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Training:   5%|▌         | 1/20 [11:22<3:36:05, 682.37s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20] - Training Loss: 3.4087, Validation Accuracy: 0.3710, Validation Loss: 2.5550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 2/20 [22:21<3:20:32, 668.49s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20] - Training Loss: 2.7423, Validation Accuracy: 0.4071, Validation Loss: 2.3727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▌        | 3/20 [33:09<3:06:47, 659.24s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20] - Training Loss: 2.6181, Validation Accuracy: 0.4346, Validation Loss: 2.2676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 4/20 [43:57<2:54:35, 654.74s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20] - Training Loss: 2.5436, Validation Accuracy: 0.4459, Validation Loss: 2.2051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  25%|██▌       | 5/20 [54:49<2:43:26, 653.75s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20] - Training Loss: 2.4806, Validation Accuracy: 0.4543, Validation Loss: 2.1541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  30%|███       | 6/20 [1:05:44<2:32:42, 654.44s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20] - Training Loss: 2.4551, Validation Accuracy: 0.4582, Validation Loss: 2.1439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  35%|███▌      | 7/20 [1:16:41<2:21:55, 655.02s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20] - Training Loss: 2.4187, Validation Accuracy: 0.4616, Validation Loss: 2.1214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  40%|████      | 8/20 [1:27:36<2:11:03, 655.25s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20] - Training Loss: 2.3979, Validation Accuracy: 0.4667, Validation Loss: 2.0942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  45%|████▌     | 9/20 [1:38:32<2:00:10, 655.47s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20] - Training Loss: 2.3812, Validation Accuracy: 0.4739, Validation Loss: 2.0628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  50%|█████     | 10/20 [1:49:34<1:49:32, 657.28s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20] - Training Loss: 2.3508, Validation Accuracy: 0.4754, Validation Loss: 2.0652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  55%|█████▌    | 11/20 [2:00:37<1:38:50, 658.98s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20] - Training Loss: 2.3371, Validation Accuracy: 0.4770, Validation Loss: 2.0437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  60%|██████    | 12/20 [2:11:40<1:28:02, 660.28s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20] - Training Loss: 2.3231, Validation Accuracy: 0.4845, Validation Loss: 2.0267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  65%|██████▌   | 13/20 [2:22:39<1:17:00, 660.00s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20] - Training Loss: 2.3193, Validation Accuracy: 0.4798, Validation Loss: 2.0362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  70%|███████   | 14/20 [2:33:49<1:06:18, 663.05s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20] - Training Loss: 2.2930, Validation Accuracy: 0.4847, Validation Loss: 2.0163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  75%|███████▌  | 15/20 [2:45:05<55:34, 666.95s/epoch]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20] - Training Loss: 2.2913, Validation Accuracy: 0.4929, Validation Loss: 2.0048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  80%|████████  | 16/20 [2:56:27<44:45, 671.34s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20] - Training Loss: 2.2715, Validation Accuracy: 0.4927, Validation Loss: 1.9945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|████████▌ | 17/20 [3:07:43<33:38, 672.86s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/20] - Training Loss: 2.2719, Validation Accuracy: 0.4990, Validation Loss: 1.9902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  90%|█████████ | 18/20 [3:19:11<22:34, 677.50s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/20] - Training Loss: 2.2578, Validation Accuracy: 0.4896, Validation Loss: 1.9862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  95%|█████████▌| 19/20 [3:30:22<11:15, 675.45s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20] - Training Loss: 2.2486, Validation Accuracy: 0.4975, Validation Loss: 1.9788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 20/20 [3:40:50<00:00, 662.55s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20] - Training Loss: 2.2355, Validation Accuracy: 0.4985, Validation Loss: 1.9565\n",
      "Fold 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:   5%|▌         | 1/20 [10:22<3:17:12, 622.78s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20] - Training Loss: 3.3973, Validation Accuracy: 0.3739, Validation Loss: 2.5349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 2/20 [20:45<3:06:48, 622.69s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20] - Training Loss: 2.7636, Validation Accuracy: 0.4196, Validation Loss: 2.3359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▌        | 3/20 [31:08<2:56:26, 622.71s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20] - Training Loss: 2.6194, Validation Accuracy: 0.4358, Validation Loss: 2.2398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 4/20 [41:31<2:46:06, 622.91s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20] - Training Loss: 2.5475, Validation Accuracy: 0.4464, Validation Loss: 2.1805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  25%|██▌       | 5/20 [51:54<2:35:45, 623.01s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20] - Training Loss: 2.4923, Validation Accuracy: 0.4494, Validation Loss: 2.1629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  30%|███       | 6/20 [1:02:21<2:25:39, 624.22s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20] - Training Loss: 2.4580, Validation Accuracy: 0.4646, Validation Loss: 2.1315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  35%|███▌      | 7/20 [1:12:45<2:15:14, 624.21s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20] - Training Loss: 2.4345, Validation Accuracy: 0.4738, Validation Loss: 2.0947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  40%|████      | 8/20 [1:23:13<2:05:04, 625.34s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20] - Training Loss: 2.4029, Validation Accuracy: 0.4765, Validation Loss: 2.0700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  45%|████▌     | 9/20 [1:33:37<1:54:34, 624.93s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20] - Training Loss: 2.3899, Validation Accuracy: 0.4742, Validation Loss: 2.0600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  50%|█████     | 10/20 [1:44:07<1:44:25, 626.50s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20] - Training Loss: 2.3711, Validation Accuracy: 0.4754, Validation Loss: 2.0596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  55%|█████▌    | 11/20 [1:54:37<1:34:08, 627.56s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20] - Training Loss: 2.3577, Validation Accuracy: 0.4867, Validation Loss: 2.0265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  60%|██████    | 12/20 [2:05:07<1:23:46, 628.34s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20] - Training Loss: 2.3511, Validation Accuracy: 0.4863, Validation Loss: 2.0207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  65%|██████▌   | 13/20 [2:15:37<1:13:21, 628.83s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20] - Training Loss: 2.3312, Validation Accuracy: 0.4878, Validation Loss: 1.9994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  70%|███████   | 14/20 [2:26:07<1:02:55, 629.20s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20] - Training Loss: 2.3155, Validation Accuracy: 0.4912, Validation Loss: 2.0082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  75%|███████▌  | 15/20 [2:36:36<52:26, 629.29s/epoch]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20] - Training Loss: 2.3123, Validation Accuracy: 0.4933, Validation Loss: 1.9865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  80%|████████  | 16/20 [2:47:07<41:59, 629.76s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20] - Training Loss: 2.3054, Validation Accuracy: 0.4956, Validation Loss: 1.9672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|████████▌ | 17/20 [2:57:37<31:29, 629.94s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/20] - Training Loss: 2.2849, Validation Accuracy: 0.4924, Validation Loss: 1.9840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  90%|█████████ | 18/20 [3:08:08<21:00, 630.26s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/20] - Training Loss: 2.2800, Validation Accuracy: 0.4952, Validation Loss: 1.9818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  95%|█████████▌| 19/20 [3:18:40<10:30, 630.55s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20] - Training Loss: 2.2634, Validation Accuracy: 0.5034, Validation Loss: 1.9506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 20/20 [3:29:11<00:00, 627.56s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20] - Training Loss: 2.2535, Validation Accuracy: 0.5040, Validation Loss: 1.9463\n",
      "Fold 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:   5%|▌         | 1/20 [10:31<3:19:57, 631.44s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20] - Training Loss: 3.3897, Validation Accuracy: 0.3582, Validation Loss: 2.5730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 2/20 [21:02<3:09:17, 630.99s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20] - Training Loss: 2.7540, Validation Accuracy: 0.4164, Validation Loss: 2.3518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▌        | 3/20 [31:32<2:58:44, 630.87s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20] - Training Loss: 2.6141, Validation Accuracy: 0.4300, Validation Loss: 2.2718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 4/20 [42:03<2:48:10, 630.66s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20] - Training Loss: 2.5379, Validation Accuracy: 0.4431, Validation Loss: 2.2164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  25%|██▌       | 5/20 [52:34<2:37:41, 630.74s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20] - Training Loss: 2.4901, Validation Accuracy: 0.4583, Validation Loss: 2.1587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  30%|███       | 6/20 [1:03:04<2:27:10, 630.75s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20] - Training Loss: 2.4532, Validation Accuracy: 0.4556, Validation Loss: 2.1433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  35%|███▌      | 7/20 [1:13:35<2:16:38, 630.63s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20] - Training Loss: 2.4249, Validation Accuracy: 0.4617, Validation Loss: 2.1149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  40%|████      | 8/20 [1:24:05<2:06:07, 630.61s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20] - Training Loss: 2.3955, Validation Accuracy: 0.4663, Validation Loss: 2.0968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  45%|████▌     | 9/20 [1:34:37<1:55:41, 631.01s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20] - Training Loss: 2.3826, Validation Accuracy: 0.4706, Validation Loss: 2.0808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  50%|█████     | 10/20 [1:45:08<1:45:08, 630.89s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20] - Training Loss: 2.3584, Validation Accuracy: 0.4644, Validation Loss: 2.0972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  55%|█████▌    | 11/20 [1:55:39<1:34:39, 631.04s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20] - Training Loss: 2.3463, Validation Accuracy: 0.4780, Validation Loss: 2.0503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  60%|██████    | 12/20 [2:06:10<1:24:06, 630.86s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20] - Training Loss: 2.3315, Validation Accuracy: 0.4780, Validation Loss: 2.0533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  65%|██████▌   | 13/20 [2:16:40<1:13:35, 630.83s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20] - Training Loss: 2.3145, Validation Accuracy: 0.4850, Validation Loss: 2.0179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  70%|███████   | 14/20 [2:27:11<1:03:04, 630.79s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20] - Training Loss: 2.3078, Validation Accuracy: 0.4890, Validation Loss: 2.0087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  75%|███████▌  | 15/20 [2:37:43<52:35, 631.11s/epoch]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20] - Training Loss: 2.2955, Validation Accuracy: 0.4825, Validation Loss: 2.0144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  80%|████████  | 16/20 [2:48:15<42:05, 631.32s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20] - Training Loss: 2.2852, Validation Accuracy: 0.4862, Validation Loss: 2.0183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|████████▌ | 17/20 [2:58:46<31:33, 631.27s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/20] - Training Loss: 2.2740, Validation Accuracy: 0.4807, Validation Loss: 2.0264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  90%|█████████ | 18/20 [3:09:17<21:02, 631.13s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/20] - Training Loss: 2.2671, Validation Accuracy: 0.4881, Validation Loss: 2.0058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  95%|█████████▌| 19/20 [3:19:47<10:30, 630.99s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20] - Training Loss: 2.2515, Validation Accuracy: 0.4915, Validation Loss: 2.0059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 20/20 [3:30:18<00:00, 630.95s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20] - Training Loss: 2.2502, Validation Accuracy: 0.4887, Validation Loss: 1.9776\n",
      "Fold 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:   5%|▌         | 1/20 [10:31<3:20:00, 631.62s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20] - Training Loss: 3.3906, Validation Accuracy: 0.3642, Validation Loss: 2.5585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 2/20 [21:01<3:09:15, 630.87s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20] - Training Loss: 2.7497, Validation Accuracy: 0.4038, Validation Loss: 2.3618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▌        | 3/20 [31:33<2:58:47, 631.03s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20] - Training Loss: 2.6348, Validation Accuracy: 0.4273, Validation Loss: 2.2569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 4/20 [42:03<2:48:13, 630.85s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20] - Training Loss: 2.5516, Validation Accuracy: 0.4092, Validation Loss: 2.3296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  25%|██▌       | 5/20 [52:37<2:37:55, 631.73s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20] - Training Loss: 2.5070, Validation Accuracy: 0.4407, Validation Loss: 2.1779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  30%|███       | 6/20 [1:03:08<2:27:22, 631.59s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20] - Training Loss: 2.4561, Validation Accuracy: 0.4568, Validation Loss: 2.1270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  35%|███▌      | 7/20 [1:13:38<2:16:44, 631.13s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20] - Training Loss: 2.4305, Validation Accuracy: 0.4589, Validation Loss: 2.1210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  40%|████      | 8/20 [1:24:09<2:06:14, 631.21s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20] - Training Loss: 2.4124, Validation Accuracy: 0.4666, Validation Loss: 2.0781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  45%|████▌     | 9/20 [1:34:41<1:55:45, 631.37s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20] - Training Loss: 2.3850, Validation Accuracy: 0.4673, Validation Loss: 2.0802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  50%|█████     | 10/20 [1:45:12<1:45:11, 631.10s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20] - Training Loss: 2.3682, Validation Accuracy: 0.4737, Validation Loss: 2.0620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  55%|█████▌    | 11/20 [1:55:42<1:34:38, 630.94s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20] - Training Loss: 2.3548, Validation Accuracy: 0.4715, Validation Loss: 2.0494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  60%|██████    | 12/20 [2:06:14<1:24:08, 631.09s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20] - Training Loss: 2.3381, Validation Accuracy: 0.4706, Validation Loss: 2.0537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  65%|██████▌   | 13/20 [2:16:44<1:13:36, 630.93s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20] - Training Loss: 2.3225, Validation Accuracy: 0.4800, Validation Loss: 2.0334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  70%|███████   | 14/20 [2:27:16<1:03:06, 631.08s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20] - Training Loss: 2.3023, Validation Accuracy: 0.4872, Validation Loss: 2.0078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  75%|███████▌  | 15/20 [2:37:47<52:35, 631.11s/epoch]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20] - Training Loss: 2.2969, Validation Accuracy: 0.4801, Validation Loss: 2.0072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  80%|████████  | 16/20 [2:48:18<42:04, 631.21s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20] - Training Loss: 2.2905, Validation Accuracy: 0.4850, Validation Loss: 2.0066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|████████▌ | 17/20 [2:58:51<31:35, 631.75s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/20] - Training Loss: 2.2848, Validation Accuracy: 0.4927, Validation Loss: 1.9899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  90%|█████████ | 18/20 [3:09:38<21:12, 636.10s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/20] - Training Loss: 2.2753, Validation Accuracy: 0.4888, Validation Loss: 1.9716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  95%|█████████▌| 19/20 [3:20:24<10:39, 639.13s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20] - Training Loss: 2.2700, Validation Accuracy: 0.4969, Validation Loss: 1.9506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 20/20 [3:31:12<00:00, 633.65s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20] - Training Loss: 2.2571, Validation Accuracy: 0.4884, Validation Loss: 1.9739\n",
      "Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:   5%|▌         | 1/20 [10:41<3:23:10, 641.61s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20] - Training Loss: 3.3885, Validation Accuracy: 0.3700, Validation Loss: 2.5555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 2/20 [21:24<3:12:37, 642.10s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20] - Training Loss: 2.7484, Validation Accuracy: 0.4053, Validation Loss: 2.3684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▌        | 3/20 [32:25<3:04:28, 651.07s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20] - Training Loss: 2.6183, Validation Accuracy: 0.4267, Validation Loss: 2.2819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 4/20 [43:17<2:53:38, 651.17s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20] - Training Loss: 2.5398, Validation Accuracy: 0.4413, Validation Loss: 2.2256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Unexpected segmentation fault encountered in worker.\n",
      "Training:  20%|██        | 4/20 [53:30<3:34:00, 802.54s/epoch]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid 35050) is killed by signal: Segmentation fault: 11. ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 70\u001b[0m\n\u001b[1;32m     67\u001b[0m val_running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mamp\u001b[38;5;241m.\u001b[39mautocast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmps\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m images, labels \u001b[38;5;129;01min\u001b[39;00m val_loader:\n\u001b[1;32m     71\u001b[0m         images \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     72\u001b[0m         labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/mambaforge/envs/2023-06-05-neuralnetworks/lib/python3.9/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/mambaforge/envs/2023-06-05-neuralnetworks/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1317\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1314\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1315\u001b[0m     \u001b[38;5;66;03m# no valid `self._rcvd_idx` is found (i.e., didn't break)\u001b[39;00m\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_persistent_workers:\n\u001b[0;32m-> 1317\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_shutdown_workers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;66;03m# Now `self._rcvd_idx` is the batch index we want to fetch\u001b[39;00m\n\u001b[1;32m   1321\u001b[0m \n\u001b[1;32m   1322\u001b[0m \u001b[38;5;66;03m# Check if the next sample has already been generated\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/2023-06-05-neuralnetworks/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1442\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._shutdown_workers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1437\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mark_worker_as_unavailable(worker_id, shutdown\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1438\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers:\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;66;03m# We should be able to join here, but in case anything went\u001b[39;00m\n\u001b[1;32m   1440\u001b[0m     \u001b[38;5;66;03m# wrong, we set a timeout and if the workers fail to join,\u001b[39;00m\n\u001b[1;32m   1441\u001b[0m     \u001b[38;5;66;03m# they are killed in the `finally` block.\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m     \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMP_STATUS_CHECK_INTERVAL\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1443\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m q \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues:\n\u001b[1;32m   1444\u001b[0m     q\u001b[38;5;241m.\u001b[39mcancel_join_thread()\n",
      "File \u001b[0;32m~/mambaforge/envs/2023-06-05-neuralnetworks/lib/python3.9/multiprocessing/process.py:149\u001b[0m, in \u001b[0;36mBaseProcess.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent_pid \u001b[38;5;241m==\u001b[39m os\u001b[38;5;241m.\u001b[39mgetpid(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcan only join a child process\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcan only join a started process\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 149\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_popen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     _children\u001b[38;5;241m.\u001b[39mdiscard(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m~/mambaforge/envs/2023-06-05-neuralnetworks/lib/python3.9/multiprocessing/popen_fork.py:40\u001b[0m, in \u001b[0;36mPopen.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmultiprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconnection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m wait\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msentinel\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     41\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# This shouldn't block if wait() returned successfully.\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/2023-06-05-neuralnetworks/lib/python3.9/multiprocessing/connection.py:936\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    933\u001b[0m     deadline \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m    935\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 936\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    937\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[1;32m    938\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [key\u001b[38;5;241m.\u001b[39mfileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n",
      "File \u001b[0;32m~/mambaforge/envs/2023-06-05-neuralnetworks/lib/python3.9/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "File \u001b[0;32m~/mambaforge/envs/2023-06-05-neuralnetworks/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py:66\u001b[0m, in \u001b[0;36m_set_SIGCHLD_handler.<locals>.handler\u001b[0;34m(signum, frame)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhandler\u001b[39m(signum, frame):\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m# This following call uses `waitid` with WNOHANG from C side. Therefore,\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m# Python can still get and update the process status successfully.\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m     \u001b[43m_error_if_any_worker_fails\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m previous_handler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     68\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(previous_handler)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid 35050) is killed by signal: Segmentation fault: 11. "
     ]
    }
   ],
   "source": [
    "# Nihat - 21 Ocak - 101 class \n",
    "# ======================= BIG MODEL TRAINING FOR 101 CLASSES ======================= #\n",
    "\n",
    "torch.backends.cudnn.enabled = False\n",
    "\n",
    "print(\"Device:\", device)\n",
    "if device == torch.device(\"cpu\"):\n",
    "    print(\"Training on CPU - not recommended!\")\n",
    "    print(\"ABORTING\")\n",
    "    exit()\n",
    "\n",
    "# Hyperparameters\n",
    "num_epochs = 20\n",
    "batch_size = 256\n",
    "num_classes = 101\n",
    "learning_rate = 0.001\n",
    "num_folds = 5\n",
    "seed = 42\n",
    "\n",
    "# Initialize KFold for cross-validation\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=seed)\n",
    "\n",
    "best_model = None\n",
    "best_val_accuracy = 0.0\n",
    "\n",
    "for fold, (train_indices, val_indices) in enumerate(kf.split(subset_train)):\n",
    "    print(f\"Fold {fold + 1}/{num_folds}\")\n",
    "\n",
    "    # Initialize model, loss function, and optimizer\n",
    "    model = CustomImageClassifier2(num_classes).to(device)\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Split the data into training and validation sets for this fold\n",
    "    train_sampler = torch.utils.data.SubsetRandomSampler(train_indices)\n",
    "    val_sampler = torch.utils.data.SubsetRandomSampler(val_indices)\n",
    "\n",
    "    train_loader = DataLoader(subset_train, batch_size=batch_size, sampler=train_sampler, pin_memory=True, num_workers=8)\n",
    "    val_loader = DataLoader(subset_train, batch_size=batch_size, sampler=val_sampler, pin_memory=True, num_workers=8)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in tqdm(range(num_epochs), desc=\"Training\", unit=\"epoch\"):\n",
    "        model.train()\n",
    "\n",
    "        running_loss = 0.0  # Initialize running loss for the epoch\n",
    "        num_batches = 0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            with torch.cuda.amp.autocast(\"mps\"):\n",
    "                outputs = model(images.to(device))\n",
    "                loss = criterion(outputs, labels.to(device))\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()  # Accumulate the loss\n",
    "            num_batches += 1\n",
    "\n",
    "        average_training_loss = running_loss / num_batches\n",
    "        \n",
    "        # Validation loop\n",
    "        model.eval()\n",
    "        total_correct = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        val_running_loss = 0.0\n",
    "\n",
    "        with torch.cuda.amp.autocast(\"mps\"):\n",
    "            for images, labels in val_loader:\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = model(images)\n",
    "                \n",
    "                loss = criterion(outputs, labels)\n",
    "                val_running_loss += loss.item()\n",
    "\n",
    "\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total_samples += labels.size(0)\n",
    "                total_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_accuracy = total_correct / total_samples\n",
    "        average_val_loss = val_running_loss / len(val_loader)\n",
    "\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}] - Training Loss: {average_training_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}, Validation Loss: {average_val_loss:.4f}\")\n",
    "\n",
    "        # Check if this model has the best validation accuracy\n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy\n",
    "            best_model = model.state_dict()\n",
    "\n",
    "# After K-fold cross-validation, use the best model for testing\n",
    "model.load_state_dict(best_model)\n",
    "model.eval()\n",
    "\n",
    "# Save the best model\n",
    "torch.save(best_model, 'bestmodel.pt')\n",
    "\n",
    "# Define the data loader for testing\n",
    "test_loader = DataLoader(subset_test, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=8)\n",
    "\n",
    "# Testing loop\n",
    "model.eval()\n",
    "total_correct = 0\n",
    "total_samples = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images.to(device))\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total_samples += labels.size(0)\n",
    "        total_correct += (predicted == labels.to(device)).sum().item()\n",
    "\n",
    "test_accuracy = total_correct / total_samples\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/2\n",
      "Fold 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/efe/miniconda3/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/efe/miniconda3/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker 12809433088 - Epoch 1/1Worker 12826259456 - Epoch 1/1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/efe/miniconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 214\u001b[0m\n\u001b[1;32m    211\u001b[0m best_val_accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;66;03m# Create threads for each fold using ThreadPoolExecutor\u001b[39;00m\n\u001b[0;32m--> 214\u001b[0m \u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mThreadPoolExecutor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mexecutor\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mexecutor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_fold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_indices\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_indices\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubset_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m# Wait for all threads to finish\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/concurrent/futures/_base.py:647\u001b[0m, in \u001b[0;36mExecutor.__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type, exc_val, exc_tb):\n\u001b[0;32m--> 647\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshutdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    648\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/concurrent/futures/thread.py:235\u001b[0m, in \u001b[0;36mThreadPoolExecutor.shutdown\u001b[0;34m(self, wait, cancel_futures)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads:\n\u001b[0;32m--> 235\u001b[0m         \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/threading.py:1119\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1116\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1119\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1121\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1122\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1123\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/threading.py:1139\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1139\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1140\u001b[0m         lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m   1141\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Efe - 21 Ocak - 101 class  -> assigning every Fold to a thread\n",
    "# ======================= BIG MODEL TRAINING FOR 101 CLASSES ======================= #\n",
    "\n",
    "# torch.backends.cudnn.enabled = False\n",
    "\n",
    "# print(\"Device:\", device)\n",
    "# if device == torch.device(\"cpu\"):\n",
    "#     print(\"Training on CPU - not recommended!\")\n",
    "#     print(\"ABORTING\")\n",
    "#     exit()\n",
    "\n",
    "# # Hyperparameters\n",
    "# num_epochs = 2      # ! Make it > 20 when you are ready to train the model for real\n",
    "# batch_size = 32\n",
    "# num_classes = 101\n",
    "# learning_rate = 0.001\n",
    "# num_folds = 5\n",
    "# seed = 42\n",
    "\n",
    "# # Initialize KFold for cross-validation\n",
    "# kf = KFold(n_splits=num_folds, shuffle=True, random_state=seed)\n",
    "\n",
    "# best_model = None\n",
    "# best_val_accuracy = 0.0\n",
    "\n",
    "# for fold, (train_indices, val_indices) in enumerate(kf.split(subset_train)):\n",
    "#     print(f\"Fold {fold + 1}/{num_folds}\")\n",
    "\n",
    "#     # Initialize model, loss function, and optimizer\n",
    "#     model = CustomImageClassifier2(num_classes).to(device)\n",
    "#     criterion = nn.CrossEntropyLoss().to(device)\n",
    "#     optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "#     # Split the data into training and validation sets for this fold\n",
    "#     train_sampler = torch.utils.data.SubsetRandomSampler(train_indices)\n",
    "#     val_sampler = torch.utils.data.SubsetRandomSampler(val_indices)\n",
    "\n",
    "#     train_loader = DataLoader(subset_train, batch_size=batch_size, sampler=train_sampler, pin_memory=True, num_workers=8)\n",
    "#     val_loader = DataLoader(subset_train, batch_size=batch_size, sampler=val_sampler, pin_memory=True, num_workers=8)\n",
    "\n",
    "#     # Training loop\n",
    "#     for epoch in tqdm(range(num_epochs), desc=\"Training\", unit=\"epoch\"):\n",
    "#         model.train()\n",
    "\n",
    "#         running_loss = 0.0  # Initialize running loss for the epoch\n",
    "#         num_batches = 0\n",
    "\n",
    "#         for images, labels in train_loader:\n",
    "#             optimizer.zero_grad()\n",
    "#             with torch.cuda.amp.autocast(\"mps\"):\n",
    "#                 outputs = model(images.to(device))\n",
    "#                 loss = criterion(outputs, labels.to(device))\n",
    "\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#             running_loss += loss.item()  # Accumulate the loss\n",
    "#             num_batches += 1\n",
    "\n",
    "#         average_training_loss = running_loss / num_batches\n",
    "        \n",
    "#         # Validation loop\n",
    "#         model.eval()\n",
    "#         total_correct = 0\n",
    "#         total_samples = 0\n",
    "\n",
    "#         val_running_loss = 0.0\n",
    "\n",
    "#         with torch.cuda.amp.autocast(\"mps\"):\n",
    "#             for images, labels in val_loader:\n",
    "#                 images = images.to(device)\n",
    "#                 labels = labels.to(device)\n",
    "\n",
    "#                 outputs = model(images)\n",
    "                \n",
    "#                 loss = criterion(outputs, labels)\n",
    "#                 val_running_loss += loss.item()\n",
    "\n",
    "\n",
    "#                 _, predicted = torch.max(outputs, 1)\n",
    "#                 total_samples += labels.size(0)\n",
    "#                 total_correct += (predicted == labels).sum().item()\n",
    "\n",
    "#         val_accuracy = total_correct / total_samples\n",
    "#         average_val_loss = val_running_loss / len(val_loader)\n",
    "\n",
    "#         print(f\"Epoch [{epoch + 1}/{num_epochs}] - Training Loss: {average_training_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}, Validation Loss: {average_val_loss:.4f}\")\n",
    "\n",
    "#         # Check if this model has the best validation accuracy\n",
    "#         if val_accuracy > best_val_accuracy:\n",
    "#             best_val_accuracy = val_accuracy\n",
    "#             best_model = model.state_dict()\n",
    "\n",
    "# # After K-fold cross-validation, use the best model for testing\n",
    "# model.load_state_dict(best_model)\n",
    "# model.eval()\n",
    "\n",
    "# # Save the best model\n",
    "# torch.save(best_model, 'bestmodel.pt')\n",
    "\n",
    "# # Define the data loader for testing\n",
    "# test_loader = DataLoader(subset_test, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=8)\n",
    "\n",
    "# # Testing loop\n",
    "# model.eval()\n",
    "# total_correct = 0\n",
    "# total_samples = 0\n",
    "# with torch.no_grad():\n",
    "#     for images, labels in test_loader:\n",
    "#         outputs = model(images.to(device))\n",
    "#         _, predicted = torch.max(outputs, 1)\n",
    "#         total_samples += labels.size(0)\n",
    "#         total_correct += (predicted == labels.to(device)).sum().item()\n",
    "\n",
    "# test_accuracy = total_correct / total_samples\n",
    "# print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Function to train a model for a fold\n",
    "def train_fold(fold, train_indices, val_indices):\n",
    "    global best_model\n",
    "    global best_val_accuracy\n",
    "\n",
    "    print(f\"Fold {fold + 1}/{num_folds}\")\n",
    "\n",
    "    # Initialize model, loss function, and optimizer\n",
    "    model = CustomImageClassifier2(num_classes).to(device)\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Split the data into training and validation sets for this fold\n",
    "    train_sampler = torch.utils.data.SubsetRandomSampler(train_indices)\n",
    "    val_sampler = torch.utils.data.SubsetRandomSampler(val_indices)\n",
    "\n",
    "    train_loader = DataLoader(subset_train, batch_size=batch_size, sampler=train_sampler, pin_memory=True, num_workers=4)\n",
    "    val_loader = DataLoader(subset_train, batch_size=batch_size, sampler=val_sampler, pin_memory=True, num_workers=4)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        # Print the worker ID\n",
    "        print(f\"Worker {threading.get_ident()} - Epoch {epoch + 1}/{num_epochs}\")\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        running_loss = 0.0  # Initialize running loss for the epoch\n",
    "        num_batches = 0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            with torch.cuda.amp.autocast(\"mps\"):\n",
    "                outputs = model(images.to(device))\n",
    "                loss = criterion(outputs, labels.to(device))\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()  # Accumulate the loss\n",
    "            num_batches += 1\n",
    "\n",
    "        average_training_loss = running_loss / num_batches\n",
    "\n",
    "        # Validation loop\n",
    "        model.eval()\n",
    "        total_correct = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        val_running_loss = 0.0\n",
    "\n",
    "        with torch.cuda.amp.autocast(\"mps\"):\n",
    "            for images, labels in val_loader:\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = model(images)\n",
    "\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_running_loss += loss.item()\n",
    "\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total_samples += labels.size(0)\n",
    "                total_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_accuracy = total_correct / total_samples\n",
    "        average_val_loss = val_running_loss / len(val_loader)\n",
    "\n",
    "        print(f\"Fold {fold + 1} - Epoch [{epoch + 1}/{num_epochs}] - Training Loss: {average_training_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}, Validation Loss: {average_val_loss:.4f}\")\n",
    "\n",
    "        # Check if this model has the best validation accuracy\n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy\n",
    "            best_model = model.state_dict()\n",
    "        \n",
    "        # Print the worker ID - finished\n",
    "        print(f\"Worker {threading.get_ident()} - Epoch {epoch + 1}/{num_epochs} finished\")\n",
    "\n",
    "# Set other hyperparameters and initialize KFold\n",
    "num_epochs = 1\n",
    "batch_size = 256\n",
    "num_classes = 101\n",
    "learning_rate = 0.001\n",
    "num_folds = 2\n",
    "seed = 42\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=seed)\n",
    "\n",
    "# Store best model and accuracy globally\n",
    "best_model = None\n",
    "best_val_accuracy = 0.0\n",
    "\n",
    "# Create threads for each fold using ThreadPoolExecutor\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    futures = [executor.submit(train_fold, fold, train_indices, val_indices) for fold, (train_indices, val_indices) in enumerate(kf.split(subset_train))]\n",
    "\n",
    "\n",
    "# Wait for all threads to finish\n",
    "for future in futures:\n",
    "    print(\"Waiting for thread to finish...\")\n",
    "    future.result()\n",
    "    print(\"Threads finished!\")\n",
    "\n",
    "# After K-fold cross-validation, use the best model for testing\n",
    "model = CustomImageClassifier2(num_classes).to(device)\n",
    "model.load_state_dict(best_model)\n",
    "model.eval()\n",
    "\n",
    "# Save the best model\n",
    "torch.save(best_model, 'bestmodel.pt')\n",
    "\n",
    "# Define the data loader for testing\n",
    "test_loader = DataLoader(subset_test, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=8)\n",
    "\n",
    "# Testing loop\n",
    "model.eval()\n",
    "total_correct = 0\n",
    "total_samples = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images.to(device))\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total_samples += labels.size(0)\n",
    "        total_correct += (predicted == labels.to(device)).sum().item()\n",
    "\n",
    "test_accuracy = total_correct / total_samples\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2023-06-05-neuralnetworks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
