{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/efe/miniconda3/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from torch.utils.data import Subset\n",
    "from torchvision import models\n",
    "import datetime\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import threading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = None\n",
    "best_val_accuracy = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_test = None\n",
    "subset_train = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ======================= NORMALIZE PARAMS ======================= #\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),  # Resize images to a consistent size\n",
    "    transforms.ToTensor(),          # Convert images to tensors\n",
    "    transforms.Normalize(           # Normalize the images\n",
    "        # average values of the red, green, \n",
    "        # and blue channels across all images in the ImageNet dataset.\n",
    "        mean=[0.485, 0.456, 0.406], \n",
    "        # standard deviation of the red, green, and blue \n",
    "        # channels across all images in the ImageNet dataset.\n",
    "        std=[0.229, 0.224, 0.225]   \n",
    "    )\n",
    "])\n",
    "\n",
    "# ======================= DATA AUGMENTATION ======================= #\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),            # Resize images to a consistent size\n",
    "    transforms.RandomHorizontalFlip(),        # Random horizontal flipping\n",
    "    transforms.RandomRotation(15),            # Random rotation by 10 degrees\n",
    "    transforms.ColorJitter(brightness=0.2,    # Adjust brightness, contrast, saturation, and hue\n",
    "                        contrast=0.2,\n",
    "                        saturation=0.2,\n",
    "                        hue=0.1),\n",
    "    transforms.ToTensor(),                    # Convert images to tensors\n",
    "    transforms.Normalize(                     # Normalize the images\n",
    "        mean=[0.485, 0.456, 0.406],           # Mean for ImageNet dataset\n",
    "        std=[0.229, 0.224, 0.225]             # Standard deviation for ImageNet dataset\n",
    "    )\n",
    "])\n",
    "\n",
    "\n",
    "# ======================= LOAD MAIN DATASET ======================= #\n",
    "# Download and load the Food101 dataset\n",
    "train_dataset = torchvision.datasets.Food101(\n",
    "    root='./data',                 # Directory to save the downloaded data\n",
    "    split='train',\n",
    "    download=True,                 # Download the data if not present\n",
    "    transform=train_transform            # Apply the train_transform to the data\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.Food101(\n",
    "    root='./data',                 # Directory to save the downloaded data\n",
    "    split='test',\n",
    "    download=True,                 # Download the data if not present\n",
    "    transform=transform            # Apply the transform to the data\n",
    ")\n",
    "\n",
    "\n",
    "def get_labels_from_loader(loader):\n",
    "    # Concatenate all labels into a single NumPy array for efficiency\n",
    "    return np.concatenate([labels.numpy() for _, labels in loader])\n",
    "\n",
    "def get_subset_with_n_classes(original_dataset, n_classes, batch_size=64):\n",
    "    # Check if the dataset is a Subset\n",
    "    if isinstance(original_dataset, Subset):\n",
    "        # Create a DataLoader with a larger batch size for efficiency\n",
    "        subset_loader = DataLoader(original_dataset, batch_size=batch_size, shuffle=False)\n",
    "        targets = get_labels_from_loader(subset_loader)\n",
    "    else:\n",
    "        # Try to access labels through the targets attribute\n",
    "        # try:\n",
    "        #     targets = np.array(original_dataset.targets)\n",
    "        # except AttributeError:\n",
    "            # Use list comprehension and NumPy for efficient label extraction\n",
    "        targets = np.array([original_dataset[i][1] for i in range(len(original_dataset))])\n",
    "\n",
    "    # Find the unique classes and select the first n\n",
    "    unique_classes = np.unique(targets)\n",
    "    selected_classes = unique_classes[:n_classes]\n",
    "\n",
    "    # Vectorized operation for selecting indices\n",
    "    selected_indices = np.where(np.isin(targets, selected_classes))[0]\n",
    "\n",
    "    # Handle if the dataset is already a Subset\n",
    "    if isinstance(original_dataset, Subset):\n",
    "        original_indices = original_dataset.indices[selected_indices]\n",
    "        subset = Subset(original_dataset.dataset, original_indices)\n",
    "    else:\n",
    "        subset = Subset(original_dataset, selected_indices)\n",
    "\n",
    "    return subset\n",
    "\n",
    "# Get a subset with the first n classes\n",
    "n = 5  # For example, get the first 5 classes\n",
    "subset_train = get_subset_with_n_classes(train_dataset, n)\n",
    "subset_test =  get_subset_with_n_classes(test_dataset, n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], device='mps:0')\n",
      "MPS device found. - Apple Silicon GPU\n",
      "Device: mps\n",
      "# ======================= TRAINING in PARALLEL ======================= #\n",
      "Fold 1 started from: Thread-14 (train_fold)\n",
      "Fold 2 started from: Thread-15 (train_fold)\n",
      "Fold 3 started from: Thread-16 (train_fold)\n",
      "Fold 4 started from: Thread-17 (train_fold)\n",
      "Fold 5 started from: Thread-18 (train_fold)\n",
      "Epoch 1 started from: Thread-17 (train_fold)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/efe/miniconda3/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/efe/miniconda3/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 started from: Thread-18 (train_fold)\n",
      "Epoch 1 started from: Thread-15 (train_fold)\n",
      "Epoch 1 started from: Thread-16 (train_fold)\n",
      "Epoch 1 started from: Thread-14 (train_fold)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-17 (train_fold):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/efe/miniconda3/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/efe/miniconda3/lib/python3.11/threading.py\", line 982, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/var/folders/95/dkw0wckj1x576p8rpy97qkv40000gn/T/ipykernel_4927/3067497005.py\", line 198, in train_fold\n",
      "NameError: name 'elapsed_time_seconds' is not defined\n",
      "Exception in thread Thread-18 (train_fold):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/efe/miniconda3/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/efe/miniconda3/lib/python3.11/threading.py\", line 982, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/var/folders/95/dkw0wckj1x576p8rpy97qkv40000gn/T/ipykernel_4927/3067497005.py\", line 198, in train_fold\n",
      "NameError: name 'elapsed_time_seconds' is not defined\n",
      "Exception in thread Thread-15 (train_fold):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/efe/miniconda3/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/efe/miniconda3/lib/python3.11/threading.py\", line 982, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/var/folders/95/dkw0wckj1x576p8rpy97qkv40000gn/T/ipykernel_4927/3067497005.py\", line 198, in train_fold\n",
      "NameError: name 'elapsed_time_seconds' is not defined\n",
      "Exception in thread Thread-14 (train_fold):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/efe/miniconda3/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/efe/miniconda3/lib/python3.11/threading.py\", line 982, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/var/folders/95/dkw0wckj1x576p8rpy97qkv40000gn/T/ipykernel_4927/3067497005.py\", line 198, in train_fold\n",
      "NameError: name 'elapsed_time_seconds' is not defined\n",
      "Exception in thread Thread-16 (train_fold):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/efe/miniconda3/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/efe/miniconda3/lib/python3.11/threading.py\", line 982, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/var/folders/95/dkw0wckj1x576p8rpy97qkv40000gn/T/ipykernel_4927/3067497005.py\", line 198, in train_fold\n",
      "NameError: name 'elapsed_time_seconds' is not defined\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2] - Training Loss: 1.0343, Validation Accuracy: 0.7040, Validation Loss: 0.7384\n",
      "Epoch [1/2] - Training Loss: 1.0021, Validation Accuracy: 0.7400, Validation Loss: 0.6863\n",
      "Epoch [1/2] - Training Loss: 1.0466, Validation Accuracy: 0.7587, Validation Loss: 0.6814\n",
      "Epoch [1/2] - Training Loss: 1.0238, Validation Accuracy: 0.7147, Validation Loss: 0.7268\n",
      "Epoch [1/2] - Training Loss: 1.0444, Validation Accuracy: 0.7400, Validation Loss: 0.6921\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Nihat - 21 Ocak - 101 class \n",
    "class CustomImageClassifier2(nn.Module):\n",
    "   def __init__(self, num_classes):\n",
    "       super(CustomImageClassifier2, self).__init__()\n",
    "      \n",
    "       # Load a pre-trained model (e.g., ResNet)\n",
    "    #    self.model = models.resnet50(weights=True)\n",
    "       self.model = models.resnet50(pretrained=True)\n",
    "\n",
    "      \n",
    "       # Freeze the parameters of the model\n",
    "       for param in self.model.parameters():\n",
    "           param.requires_grad = False\n",
    "\n",
    "\n",
    "       # Assuming ResNet18 is used, the in_features for the first added linear layer\n",
    "       in_features = self.model.fc.in_features\n",
    "\n",
    "\n",
    "       # Replace the fully connected layer\n",
    "       self.model.fc = nn.Sequential(\n",
    "           nn.Linear(in_features, 1024),\n",
    "           nn.ReLU(),\n",
    "           nn.BatchNorm1d(1024),\n",
    "           nn.Dropout(0.5),\n",
    "           nn.Linear(1024, 512),\n",
    "           nn.ReLU(),\n",
    "           nn.BatchNorm1d(512),\n",
    "           nn.Dropout(0.5),\n",
    "           nn.Linear(512, 256),\n",
    "           nn.ReLU(),\n",
    "           nn.BatchNorm1d(256),\n",
    "           nn.Dropout(0.5),\n",
    "           nn.Linear(256, num_classes)\n",
    "       )\n",
    "\n",
    "\n",
    "   def forward(self, x):\n",
    "       return self.model(x)\n",
    "   \n",
    "\n",
    "# ======================= TRAINING ======================= #\n",
    "   \n",
    "\n",
    "# Function to train a model for a fold\n",
    "def train_fold(fold, train_indices, val_indices, num_folds, num_epochs, batch_size, num_classes, learning_rate, device, subset_train):\n",
    "    global best_model\n",
    "    global best_val_accuracy\n",
    "\n",
    "    # Print fold started from the thread\n",
    "    print(f\"Fold {fold + 1} started from: {threading.current_thread().name}\")\n",
    "\n",
    "    # Initialize model, loss function, and optimizer\n",
    "    model = CustomImageClassifier2(num_classes).to(device)\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    # model = CustomImageClassifier2(num_classes)\n",
    "    # criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Split the data into training and validation sets for this fold\n",
    "    train_sampler = torch.utils.data.SubsetRandomSampler(train_indices)\n",
    "    val_sampler = torch.utils.data.SubsetRandomSampler(val_indices)\n",
    "\n",
    "    train_loader = DataLoader(subset_train, batch_size=batch_size, sampler=train_sampler, pin_memory=True, num_workers=4)\n",
    "    val_loader = DataLoader(subset_train, batch_size=batch_size, sampler=val_sampler, pin_memory=True, num_workers=4)\n",
    "\n",
    "    # For each epoch keep array of accuracies\n",
    "    train_losses = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    # try:\n",
    "\n",
    "        # # Training loop\n",
    "        # for epoch in range(num_epochs):\n",
    "            \n",
    "        #     # Get time stamp\n",
    "        #     start_time = time.time()\n",
    "\n",
    "        #     # Print epoch started from the thread\n",
    "        #     print(f\"Epoch {epoch + 1} started from: {threading.current_thread().name}\")\n",
    "\n",
    "        #     model.train()\n",
    "            \n",
    "        #     running_loss = 0.0\n",
    "        #     num_batches = 0\n",
    "\n",
    "        #     for images, labels in train_loader:\n",
    "        #         optimizer.zero_grad()\n",
    "        #         # No need for to(device) here\n",
    "        #         outputs = model(images)\n",
    "        #         loss = criterion(outputs, labels)\n",
    "        #         loss.backward()\n",
    "        #         optimizer.step()\n",
    "        #         running_loss += loss.item()\n",
    "        #         num_batches += 1\n",
    "\n",
    "        #     average_training_loss = running_loss / num_batches\n",
    "\n",
    "        #     # Validation loop\n",
    "        #     model.eval()\n",
    "        #     total_correct = 0\n",
    "        #     total_samples = 0\n",
    "        #     val_running_loss = 0.0\n",
    "\n",
    "        #     for images, labels in val_loader:\n",
    "        #         # No need for to(device) here\n",
    "        #         outputs = model(images)\n",
    "        #         loss = criterion(outputs, labels)\n",
    "        #         val_running_loss += loss.item()\n",
    "        #         _, predicted = torch.max(outputs, 1)\n",
    "        #         total_samples += labels.size(0)\n",
    "        #         total_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        #     val_accuracy = total_correct / total_samples\n",
    "        #     average_val_loss = val_running_loss / len(val_loader)\n",
    "\n",
    "        #     print(f\"Epoch [{epoch + 1}/{num_epochs}] - Training Loss: {average_training_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}, Validation Loss: {average_val_loss:.4f}\")\n",
    "\n",
    "        #     # Append the accuracies\n",
    "        #     train_losses.append(average_training_loss)\n",
    "        #     val_accuracies.append(val_accuracy)\n",
    "\n",
    "        #     # Check if this model has the best validation accuracy\n",
    "        #     if val_accuracy > best_val_accuracy:\n",
    "        #         best_val_accuracy = val_accuracy\n",
    "        #         best_model = model.state_dict()\n",
    "\n",
    "        #     # Calculate the time elapsed in seconds\n",
    "        #     end_time = time.time()\n",
    "        #     elapsed_time_seconds = end_time - start_time\n",
    "\n",
    "        #     # Print epoch finished from the thread\n",
    "        #     print(f\"Epoch {epoch + 1} finished from: {threading.current_thread().name}\" + \"\\n\" + \"Time elapsed:\", elapsed_time_seconds)\n",
    "\n",
    "\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        # Get time stamp\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Print epoch started from the thread\n",
    "        print(f\"Epoch {epoch + 1} started from: {threading.current_thread().name}\")\n",
    "\n",
    "        model.train()\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        num_batches = 0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images.to(device))\n",
    "            loss = criterion(outputs, labels.to(device))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            num_batches += 1\n",
    "\n",
    "        average_training_loss = running_loss / num_batches\n",
    "\n",
    "        # print(\"here1\")\n",
    "\n",
    "        # Validation loop\n",
    "        model.eval()\n",
    "        total_correct = 0\n",
    "        total_samples = 0\n",
    "        val_running_loss = 0.0\n",
    "\n",
    "        for images, labels in val_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_samples += labels.size(0)\n",
    "            total_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # print(\"here2\")\n",
    "\n",
    "        val_accuracy = total_correct / total_samples\n",
    "        average_val_loss = val_running_loss / len(val_loader)\n",
    "\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}] - Training Loss: {average_training_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}, Validation Loss: {average_val_loss:.4f}\")\n",
    "\n",
    "        # Append the accuracies\n",
    "        train_losses.append(average_training_loss)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "\n",
    "        # Check if this model has the best validation accuracy\n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy\n",
    "            best_model = model.state_dict()\n",
    "\n",
    "        # Calculate the time elapsed in seconds\n",
    "        end_time = time.time()    \n",
    "        elapsed_time_seconds = end_time - start_time\n",
    "        elapsed_time = datetime.timedelta(seconds=elapsed_time_seconds) \n",
    "\n",
    "\n",
    "        # Print epoch finished from the thread\n",
    "        print(f\"Epoch {epoch + 1} finished from: {threading.current_thread().name}\" + \"\\n\" + \"Time elapsed:\", elapsed_time)\n",
    "\n",
    "    # except KeyboardInterrupt:\n",
    "    #     print(\"Training interrupted. Saving the best model...\")\n",
    "    #     if best_model is not None:\n",
    "    #         torch.save(best_model, 'bestmodel_interrupted.pt')\n",
    "    #     else:\n",
    "    #         print(\"No best model found\")\n",
    "\n",
    "    # Print fold finished from the thread\n",
    "    print(f\"Fold {fold + 1} finished from: {threading.current_thread().name}\")\n",
    "\n",
    "    # Print the arrays\n",
    "    print(\"From thread:\", threading.current_thread().name + \"\\n\" + \"Train losses:\", train_losses, \"\\n\" + \"Validation accuracies:\", val_accuracies)\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    # ======================= PYTHON SETTINGS ======================= #\n",
    "    # =======================   GPU or CPU    ======================= #\n",
    "\n",
    "    device = torch.device(\"cpu\")\n",
    "    # torch.multiprocessing.set_start_method('file_system')\n",
    "\n",
    "    # Check if GPU is available -> CUDA\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        print(\"There are %d GPU(s) available.\" % torch.cuda.device_count())\n",
    "        print(\"We will use the GPU:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "    # Apple Silicon GPU\n",
    "    if torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "        out = torch.ones(1, device=device)\n",
    "        print (out)\n",
    "        print (\"MPS device found. - Apple Silicon GPU\")\n",
    "    else:\n",
    "        print (\"MPS device not found.\")\n",
    "\n",
    "\n",
    "    print(\"Device:\", device)\n",
    "\n",
    "    # =======================   Ranom Seeds   ======================= #\n",
    "    # Set random seed for reproducibility\n",
    "    seed = 42\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    # =============================================================== #\n",
    "\n",
    "\n",
    "\n",
    "    # Get a subset with the first n classes\n",
    "    # n = 5  # For example, get the first 5 classes\n",
    "    # subset_train = train_dataset\n",
    "    # subset_test = test_dataset\n",
    "\n",
    "    # Set other hyperparameters and initialize KFold\n",
    "    num_epochs = 2\n",
    "    batch_size = 32\n",
    "    num_classes = 5 # ! 101\n",
    "    learning_rate = 0.001\n",
    "    num_folds = 5\n",
    "    seed = 42\n",
    "    kf = KFold(n_splits=num_folds, shuffle=True, random_state=seed)\n",
    "\n",
    "\n",
    "    global best_model\n",
    "    global best_val_accuracy\n",
    "    global subset_train\n",
    "    global subset_test\n",
    "\n",
    "\n",
    "    # ======================= TRAINING in PARALLEL ======================= #\n",
    "    print(\"# ======================= TRAINING in PARALLEL ======================= #\")\n",
    "    # Create a thread pool\n",
    "    for fold, (train_indices, val_indices) in enumerate(kf.split(subset_train)):\n",
    "        # Create a thread for each fold\n",
    "        t = threading.Thread(target=train_fold, args=(fold, train_indices, val_indices, num_folds, num_epochs, batch_size, num_classes, learning_rate, device, subset_train))\n",
    "        t.start()\n",
    "\n",
    "    # Wait for all threads to finish\n",
    "    main_thread = threading.current_thread()\n",
    "    for t in threading.enumerate():\n",
    "        if t is not main_thread:\n",
    "            t.join()\n",
    "\n",
    "\n",
    "    # After K-fold cross-validation, use the best model for testing\n",
    "    model = CustomImageClassifier2(num_classes).to(device)\n",
    "    if best_model is not None:\n",
    "        model.load_state_dict(best_model)\n",
    "    else:\n",
    "        print(\"No best model found\")\n",
    "        return\n",
    "    model.eval()\n",
    "\n",
    "    # Save the best model\n",
    "    torch.save(best_model, 'bestmodel.pt')\n",
    "\n",
    "    # Define the data loader for testing\n",
    "    test_loader = DataLoader(subset_test, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=2)\n",
    "\n",
    "    # Testing loop\n",
    "    model.eval()\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            outputs = model(images.to(device))\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_samples += labels.size(0)\n",
    "            total_correct += (predicted == labels.to(device)).sum().item()\n",
    "\n",
    "    test_accuracy = total_correct / total_samples\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "    print(\"Done!\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Start time get\n",
    "    start_time = time.time()\n",
    "    main()\n",
    "    # End time get\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Time elapsed\n",
    "    elapsed_time_seconds = end_time - start_time\n",
    "    elapsed_time = datetime.timedelta(seconds=elapsed_time_seconds)\n",
    "\n",
    "    print(\"Time elapsed:\", elapsed_time)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
